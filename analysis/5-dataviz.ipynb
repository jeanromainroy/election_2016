{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataviz Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have labeled tweets for different states and days we can prepare this data to be visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "import json \n",
    "from glob import glob\n",
    "\n",
    "from libs.states import states\n",
    "from libs.states import countStates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now collect all the predictions files and reorganize them by state/day/party count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPreds():\n",
    "    \n",
    "    # Glob all the tweet predictions csv\n",
    "    filenames = glob(\"data/general/*/predictions.csv\")\n",
    "\n",
    "    # Go through predictions files\n",
    "    for fname in filenames:\n",
    "        \n",
    "        # Get created_at from filepath\n",
    "        created_at = fname.split(\"/\")[-2]\n",
    "        print(\"--- \" + created_at + \" ---\")\n",
    "        \n",
    "        # Count the number of tweets per state\n",
    "        states_counts = countStates(fname)\n",
    "        \n",
    "        total = 0\n",
    "        for k, v in states_counts.items():\n",
    "            print(str(k) + \": \" + str(v))\n",
    "            total = total + v[0] + v[1]\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print(\"TOTAL: \" + str(total) + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glob all the tweet predictions csv\n",
    "filenames = glob(\"data/general/*/predictions.csv\")\n",
    "\n",
    "# init object\n",
    "dataframe = []\n",
    "\n",
    "# Go through predictions files\n",
    "for fname in filenames:\n",
    "    \n",
    "    # Get created_at from filepath\n",
    "    created_at = fname.split(\"/\")[-2]\n",
    "    \n",
    "    # Count the number of tweets per state\n",
    "    states_counts = countStates(fname)\n",
    "    \n",
    "    # init entry\n",
    "    entry = {\n",
    "        \"created_at\": created_at,\n",
    "        \"states\":states_counts\n",
    "    }\n",
    "    \n",
    "    # Add to final obj\n",
    "    dataframe.append(entry)\n",
    "    \n",
    "    \n",
    "# convert into JSON:\n",
    "dataframe = json.dumps(dataframe)\n",
    "\n",
    "# Write to file\n",
    "out_path = 'data/dataviz/data_cnn.json'\n",
    "with open(out_path, 'w+', newline='', encoding=\"utf-8\") as outfile:\n",
    "    outfile.write(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
